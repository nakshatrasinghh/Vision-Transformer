{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnM0ZjBR7EA4"
      },
      "source": [
        "#***Vision Transformer using TensorFlow 2.0***\n",
        "\n",
        "By Nakshatra Singh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuxOw3gU7_z5"
      },
      "source": [
        "# Using Google GPU for Training\n",
        "Google colab offers free GPUs and TPUs! Since we'll be training a large model it's best to take advantage of this (in this case we'll use GPU), otherwise training can take long time.\n",
        "\n",
        "A GPU can be added by going to the menu and selecting:\n",
        "\n",
        "`Edit -> Notebook Settings -> Hardware Accelerator -> (GPU)`\n",
        "\n",
        "Then run the following cell to confirm that a GPU is detected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN3XL5pC8Z23",
        "outputId": "799e91af-60d6-4634-bae7-e8107527b983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "# Get the device GPU name \n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at : {}'.format(device_name)) \n",
        "else:\n",
        "  raise SystemError('GPU not found!') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at : /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQR1GCgn8npp"
      },
      "source": [
        "Firstly, we'll install a flexible and powerful python package for tensor operations to provide readable and reliable code. Supports numpy, pytorch and tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfQyjvfCzamG",
        "outputId": "086d779d-f854-4960-e16c-928a3a8b5e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "!pip install einops==0.3.0 "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting einops==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJMKEXsP9efJ"
      },
      "source": [
        "We'll be using the tensorflow.keras.datasets module which provides a few toy datasets (already-vectorized, in Numpy format) that can be used for debugging a model or creating simple code examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ovHBUtDzZj8",
        "outputId": "0b38309b-b960-4f00-d40c-0c157f5b97a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from tensorflow.keras import datasets\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN7zBA-7-JN-"
      },
      "source": [
        "Now, we'll cast the vectorized numpy arrays (in case of Tensor) or x.values (in case of SparseTensor or IndexedSlices) to .*float32* dtype and also reshape it to `n 32x32 RGB images`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-konU2DCzXWc"
      },
      "source": [
        "train_images = tf.cast(train_images.reshape((-1, 3, 32, 32)), dtype=tf.float32)\n",
        "test_images = tf.cast(test_images.reshape((-1, 3, 32, 32)), dtype=tf.float32)\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsCJnU7x_TSq"
      },
      "source": [
        "Now, With the help of `tf.data.Dataset.from_tensor_slices()` method, we can get the slices of an array in the form of objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM880gSRzn5C"
      },
      "source": [
        "# Simplest way to create a train dataset is to create it from a python list\n",
        "train_x = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "train_y = tf.data.Dataset.from_tensor_slices(train_labels)\n",
        "\n",
        "# Zip it together\n",
        "train_dataset = tf.data.Dataset.zip((train_x, train_y))\n",
        "test_x = tf.data.Dataset.from_tensor_slices(test_images)\n",
        "\n",
        "# Simplest way to create a test dataset is to create it from a python list\n",
        "test_y = tf.data.Dataset.from_tensor_slices(test_labels)\n",
        "test_dataset = tf.data.Dataset.zip((test_x, test_y)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxIKoMVvAS9a"
      },
      "source": [
        "We'll import the `TrainerConfig` class from the trainer.py file and set up the model optimization parameters. You can definitely change these parameters to achieve SOTA performance according to your problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64AR7rpZzp2i"
      },
      "source": [
        "from trainer import TrainerConfig \n",
        "\n",
        "tconf = TrainerConfig(max_epochs=10, batch_size=64, learning_rate=1e-3) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHkGTIx9Ayjl"
      },
      "source": [
        "We'll also initialize a sample model config which we will use for training the ViT model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwH9Pabhzsni"
      },
      "source": [
        "# NOTE: image dimensions must be divisible by the patch size\n",
        "model_config = {\"image_size\":32,\n",
        "                \"patch_size\":4,\n",
        "                \"num_classes\":10,\n",
        "                \"dim\":64,\n",
        "                \"depth\":3,\n",
        "                \"heads\":4,\n",
        "                \"mlp_dim\":128} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQwScHWnBQjc"
      },
      "source": [
        "We'll import the `Trainer` class from the trainer.py file and `ViT` class from model.py file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwwviP2-zuh6"
      },
      "source": [
        "from trainer import Trainer\n",
        "from model import ViT\n",
        "\n",
        "trainer = Trainer(ViT, model_config, train_dataset, len(train_images), test_dataset, len(test_images), tconf) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq11ZpRMBv8f"
      },
      "source": [
        "Finally, we'll train our CIFAR10 dataset, the performance is below average. The main purpose of the notebook is to demonstrate how to use Vision Transformers using Tensorflow 2.0, the authors of the [paper](https://arxiv.org/abs/2006.03677) have achieved SOTA performace with this amazing technique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlDWovb2zv3R",
        "outputId": "b1f0a09c-4740-4943-dbae-1b498c9f418c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "trainer.train() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1-> Train Loss 1.78300. Train Accuracy 0.34862\n",
            "Epoch 1-> Test Loss 1.54439. Test Accuracy 0.43700\n",
            "Epoch 2-> Train Loss 1.50706. Train Accuracy 0.45196\n",
            "Epoch 2-> Test Loss 1.44042. Test Accuracy 0.47530\n",
            "Epoch 3-> Train Loss 1.41017. Train Accuracy 0.48946\n",
            "Epoch 3-> Test Loss 1.40274. Test Accuracy 0.49240\n",
            "Epoch 4-> Train Loss 1.34558. Train Accuracy 0.51278\n",
            "Epoch 4-> Test Loss 1.38715. Test Accuracy 0.49490\n",
            "Epoch 5-> Train Loss 1.29309. Train Accuracy 0.53382\n",
            "Epoch 5-> Test Loss 1.39821. Test Accuracy 0.49330\n",
            "Epoch 6-> Train Loss 1.25046. Train Accuracy 0.54902\n",
            "Epoch 6-> Test Loss 1.37738. Test Accuracy 0.50480\n",
            "Epoch 7-> Train Loss 1.21084. Train Accuracy 0.56498\n",
            "Epoch 7-> Test Loss 1.36944. Test Accuracy 0.50970\n",
            "Epoch 8-> Train Loss 1.18018. Train Accuracy 0.57266\n",
            "Epoch 8-> Test Loss 1.36997. Test Accuracy 0.51350\n",
            "Epoch 9-> Train Loss 1.15001. Train Accuracy 0.58420\n",
            "Epoch 9-> Test Loss 1.38436. Test Accuracy 0.51770\n",
            "Epoch 10-> Train Loss 1.11912. Train Accuracy 0.59814\n",
            "Epoch 10-> Test Loss 1.40490. Test Accuracy 0.51090\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}